import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import requests
import fitz  # PyMuPDF
import re
import os

# ==========================================
# âš™ï¸ AYARLAR
# ==========================================

CREDENTIALS_FILE = 'credentials.json'

# Google Sheet Dosya AdÄ±
SHEET_NAME = 'Ä°ZMÄ°R CV Form'

# ğŸ”’ GÃœVENLÄ°K GÃœNCELLEMESÄ°:
# Token artÄ±k kodun iÃ§inde deÄŸil, .streamlit/secrets.toml dosyasÄ±ndan okunuyor.
try:
    TYPEFORM_ACCESS_TOKEN = st.secrets["general"]["typeform_token"]
except FileNotFoundError:
    st.error("âš ï¸ HATA: .streamlit/secrets.toml dosyasÄ± bulunamadÄ±! Token okunamÄ±yor.")
    st.stop()
except KeyError:
    st.error("âš ï¸ HATA: secrets.toml dosyasÄ±nda 'typeform_token' alanÄ± eksik.")
    st.stop()

# SÃ¼tun Ä°simleri
COLUMN_PDF_URL_BASE = "Global Talent ProgramÄ± iÃ§in CV'nizi ingilizce olacak ÅŸekilde PDF formatÄ±nda buraya yÃ¼kleyebilirsiniz."
COLUMN_TOKEN_ID = "Token"
COLUMN_NAME = "Ad ve Soyad"
COLUMN_DEPARTMENT = "Hangi alanda staja baÅŸvurmak istiyorsunuz ?"


# ==========================================
# ğŸ› ï¸ YARDIMCI FONKSÄ°YONLAR
# ==========================================

# --- 1. Google Sheets BaÄŸlantÄ±sÄ± ----

@st.cache_data(ttl=600)
def load_data():
    try:
        scopes = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]

        # Ã–NCE BULUTTAKÄ° SECRETS'A BAK, YOKSA YEREL DOSYAYA BAK
        if "gcp_service_account" in st.secrets:
            # Bulut OrtamÄ± (Streamlit Cloud)
            creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
        else:
            # Yerel Ortam (BilgisayarÄ±n)
            creds = Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=scopes)

        client = gspread.authorize(creds)

        try:
            spreadsheet = client.open(SHEET_NAME)
        except gspread.exceptions.SpreadsheetNotFound:
            st.error(f"âŒ '{SHEET_NAME}' dosyasÄ± bulunamadÄ±!")
            return pd.DataFrame()

        try:
            sheet = spreadsheet.worksheet("Ä°ZMÄ°R CV Form")
        except gspread.exceptions.WorksheetNotFound:
            st.error("âŒ 'Ä°ZMÄ°R CV Form' sekmesi bulunamadÄ±.")
            return pd.DataFrame()

        data = sheet.get_all_values()

        if not data:
            return pd.DataFrame()

        original_headers = data[0]
        rows = data[1:]

        # SÃ¼tun isimlerini dÃ¼zeltme (Duplicate hatasÄ± iÃ§in)
        seen_headers = {}
        unique_headers = []
        for col in original_headers:
            if col in seen_headers:
                seen_headers[col] += 1
                unique_headers.append(f"{col}_{seen_headers[col]}")
            else:
                seen_headers[col] = 0
                unique_headers.append(col)

        df = pd.DataFrame(rows, columns=unique_headers)
        return df

    except Exception as e:
        st.error(f"Veri YÃ¼kleme HatasÄ±: {e}")
        return pd.DataFrame()

    except Exception as e:
        st.error(f"Veri YÃ¼kleme HatasÄ±: {e}")
        return pd.DataFrame()


# --- 2. Ä°ÅŸlenmiÅŸ Token YÃ¶netimi ---
def get_processed_tokens():
    if os.path.exists("processed_tokens.txt"):
        with open("processed_tokens.txt", "r") as f:
            return f.read().splitlines()
    return []


def save_token(token):
    with open("processed_tokens.txt", "a") as f:
        f.write(f"{token}\n")


# --- 3. PDF Ä°ndirme ve SansÃ¼rleme Motoru ---
def sanitize_pdf(pdf_url):
    try:
        headers = {
            "Authorization": f"Bearer {TYPEFORM_ACCESS_TOKEN}",
            "User-Agent": "Mozilla/5.0"
        }

        response = requests.get(pdf_url, headers=headers)

        if response.status_code != 200:
            st.error(f"Ä°ndirme hatasÄ±! Kod: {response.status_code}")
            return None

        pdf_data = response.content

        try:
            doc = fitz.open(stream=pdf_data, filetype="pdf")
        except:
            st.error("Dosya indirildi ama PDF deÄŸil.")
            return None

        email_pattern = r"[\w\.-]+@[\w\.-]+"
        phone_pattern = r"(\+90|0)?\s*[0-9]{3}\s*[0-9]{3}\s*[0-9]{2}\s*[0-9]{2}"

        redaction_count = 0

        for page in doc:
            text = page.get_text("text")
            sensitive_data = re.findall(email_pattern, text) + re.findall(phone_pattern, text)

            for item in sensitive_data:
                if isinstance(item, tuple): item = item[0]
                if not item: continue
                areas = page.search_for(item)
                for area in areas:
                    page.add_redact_annot(area, fill=(0, 0, 0))
                    redaction_count += 1
            page.apply_redactions()

        st.info(f"Toplam {redaction_count} adet hassas bilgi silindi.")
        return doc.tobytes()

    except Exception as e:
        st.error(f"PDF Ä°ÅŸleme HatasÄ±: {e}")
        return None


# ==========================================
# ğŸ–¥ï¸ ARAYÃœZ
# ==========================================

st.set_page_config(page_title="Ä°zmir CV Form Havuzu", layout="wide")
st.title("ğŸ›¡ï¸ Ä°zmir CV Form - GÃ¼venli Havuz")
st.markdown("---")

st.sidebar.header("ğŸ›ï¸ Filtreleme Paneli")

df = load_data()

if not df.empty:

    dept_col = next((col for col in df.columns if col.startswith(COLUMN_DEPARTMENT)), None)
    name_col = next((col for col in df.columns if col.startswith(COLUMN_NAME)), None)
    all_cv_cols = [col for col in df.columns if col.startswith(COLUMN_PDF_URL_BASE)]

    if dept_col:
        dept_list = df[df[dept_col] != ""][dept_col].unique()
        selected_depts = st.sidebar.multiselect("Departman SeÃ§", dept_list, default=dept_list)
        filtered_df = df[df[dept_col].isin(selected_depts)]
    else:
        st.sidebar.warning(f"Departman sÃ¼tunu ({COLUMN_DEPARTMENT}) bulunamadÄ±.")
        filtered_df = df

    st.sidebar.info(f"Listelenen Aday: {len(filtered_df)}")
    st.dataframe(filtered_df, use_container_width=True)

    st.subheader("âš™ï¸ CV Ä°ÅŸlemleri")

    col1, col2 = st.columns([1, 2])

    with col1:
        if name_col:
            candidate_options = filtered_df[name_col].tolist()
            selected_candidate_name = st.selectbox("Aday SeÃ§iniz:", candidate_options)
        else:
            st.error("Ä°sim sÃ¼tunu bulunamadÄ±.")
            selected_candidate_name = None

    with col2:
        if selected_candidate_name and st.button("SeÃ§ili AdayÄ± Ä°ncele ve SansÃ¼rle"):

            row = filtered_df[filtered_df[name_col] == selected_candidate_name].iloc[0]
            token = str(row.get(COLUMN_TOKEN_ID, "NoToken"))

            pdf_url = ""
            for col in all_cv_cols:
                val = str(row.get(col, "")).strip()
                if val and "http" in val:
                    pdf_url = val
                    break

            processed_list = get_processed_tokens()

            if token in processed_list:
                st.warning(f"âš ï¸ Bu aday ({token}) daha Ã¶nce iÅŸlenmiÅŸ.")

            if not pdf_url:
                st.error("âŒ Bu kiÅŸi iÃ§in hiÃ§bir sÃ¼tunda CV linki bulunamadÄ±.")
            else:
                with st.spinner(f'PDF Bulundu, Ä°ÅŸleniyor...'):
                    sanitized_bytes = sanitize_pdf(pdf_url)

                    if sanitized_bytes:
                        st.success("âœ… Ä°ÅŸlem BaÅŸarÄ±lÄ±!")
                        st.download_button(
                            label="ğŸ“¥ GÃ¼venli CV'yi Ä°ndir (PDF)",
                            data=sanitized_bytes,
                            file_name=f"{selected_candidate_name}_Cleaned.pdf",
                            mime="application/pdf"
                        )
                        if token not in processed_list:
                            save_token(token)
else:
    st.warning("Veri yÃ¼klenemedi. .streamlit/secrets.toml ve credentials.json dosyalarÄ±nÄ± kontrol et.")