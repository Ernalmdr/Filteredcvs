import time
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload
import io
import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import requests
import fitz  # PyMuPDF
import re
import os
import json
import google.generativeai as genai
from fpdf import FPDF
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ==========================================
# ‚öôÔ∏è AYARLAR
# ==========================================

CREDENTIALS_FILE = 'credentials.json'
SHEET_NAME = 'ƒ∞ZMƒ∞R CV Form'
ALLOWED_CATEGORIES = ["Engineering", "Marketing", "HR", "Finance", "Sales", "IT", "Design"]

try:
    TYPEFORM_ACCESS_TOKEN = st.secrets["general"]["typeform_token"]
    ADMIN_PASSWORD = st.secrets["general"]["admin_password"]
    GEMINI_API_KEY = st.secrets["general"]["gemini_api_key"]

    # Gemini Ayarlarƒ±
    genai.configure(api_key=GEMINI_API_KEY)

except Exception as e:
    st.error(f"‚ö†Ô∏è HATA: secrets.toml ayarlarƒ± eksik: {e}")
    st.stop()

# S√ºtun ƒ∞simleri
COLUMN_PDF_URL_BASE = "Global Talent Programƒ± i√ßin CV'nizi ingilizce olacak ≈üekilde PDF formatƒ±nda buraya y√ºkleyebilirsiniz."
COLUMN_TOKEN_ID = "Token"
COLUMN_NAME = "Ad ve Soyad"
COLUMN_DEPARTMENT = "Hangi alanda staja ba≈üvurmak istiyorsunuz ?"


def get_drive_service():
    scopes = ["https://www.googleapis.com/auth/drive"]
    if "gcp_service_account" in st.secrets:
        creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
    else:
        creds = Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=scopes)
    return build('drive', 'v3', credentials=creds)


def get_or_create_drive_folder(service, folder_name, parent_id):
    query = f"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false and '{parent_id}' in parents"
    results = service.files().list(q=query, supportsAllDrives=True, includeItemsFromAllDrives=True).execute().get(
        'files', [])
    if results: return results[0]['id']

    meta = {'name': folder_name, 'mimeType': 'application/vnd.google-apps.folder', 'parents': [parent_id]}
    folder = service.files().create(body=meta, fields='id', supportsAllDrives=True).execute()
    return folder.get('id')


def upload_to_drive(service, file_bytes, file_name, categories):
    root_id = st.secrets["general"].get("root_folder_id")
    # Eƒüer Gemini kategori bulamazsa "Others" kullan
    final_categories = categories if categories else ["Others"]

    for cat in final_categories:
        folder_id = get_or_create_drive_folder(service, cat, root_id)
        media = MediaIoBaseUpload(io.BytesIO(file_bytes), mimetype='application/pdf')
        file_meta = {'name': file_name, 'parents': [folder_id]}
        service.files().create(body=file_meta, media_body=media, supportsAllDrives=True).execute()
    return True

# ==========================================
# üß† YAPAY ZEKA & PDF OLU≈ûTURUCU
# ==========================================

@st.cache_data(show_spinner=False)
def extract_data_with_gemini(text_content):
    """Daƒüƒ±nƒ±k CV metnini standart JSON formatƒ±na √ßevirir."""

    # 'flash' modeli en hƒ±zlƒ±sƒ±dƒ±r.
    model = genai.GenerativeModel('gemini-3-flash-preview')

    # ALLOWED_CATEGORIES ve text_content deƒüi≈ükenlerinin tanƒ±mlƒ± olduƒüunu varsayƒ±yorum.

    prompt = f"""
        Act as a professional HR expert and Resume Writer. 
        Your goal is to extract data from the provided CV and ENHANCE it to make the candidate stand out.

        STRICT RULES FOR ENHANCEMENT:
        1. PROFESSIONAL TONE: Use strong action verbs (e.g., "Spearheaded", "Optimized", "Engineered").
        2. QUANTIFIABLE IMPACT: Where possible, transform descriptions into achievement-based statements using numerical data (percentages, time saved, budget managed). If specific numbers aren't present, use placeholders or professional phrasing that implies scale.
        3. SUMMARY: Rewrite the 'summary' to be a powerful elevator pitch.
        4. EXPERIENCE: Rewrite job descriptions to focus on results rather than just duties.

        Pick one or more categories for 'suggested_categories' ONLY from this list: {ALLOWED_CATEGORIES}.
        Return ONLY JSON. No markdown formatting. If missing, leave empty. 

        JSON Schema:
        {{
            "name": "Full Name",
            "suggested_categories": ["Category from the list"],
            "title": "Professional Title",
            "location": "City",
            "summary": "Enhanced professional summary with a focus on value proposition",
            "education": [{{ "degree": "", "school": "", "year": "" }}],
            "experience": [{{ 
                "role": "", 
                "company": "", 
                "description": "Enhanced description with numerical achievements and action verbs" 
            }}],
            "skills": {{ "tech": "List of technical skills" }},
            "spoken_languages": "List"
        }}

        CV TEXT:
        {text_content}
        """

    try:
        response = model.generate_content(prompt)
        json_str = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(json_str)
    except Exception as e:
        return None


class PDF(FPDF):
    def __init__(self, font_family='Arial'):
        super().__init__()
        self.font_family = font_family

    def header(self):
        pass

    def section_title(self, label):
        # 'B' (Bold) i√ßin font ailesi desteƒüi gerekir.
        # Eƒüer √∂zel font (DejaVu) kullanƒ±yorsan ve Bold dosyasƒ±nƒ± y√ºklemediysen
        # standart Arial'a d√º≈üebilir veya hata verebilir.
        # G√ºvenlik i√ßin burada font_family deƒüi≈ükenini kullanƒ±yoruz.
        self.set_font(self.font_family, 'B', 12)
        self.set_text_color(0, 51, 102)
        self.cell(0, 10, label, 0, 1, 'L')
        self.line(10, self.get_y(), 200, self.get_y())
        self.ln(2)

    def section_body(self, text):
        self.set_font(self.font_family, '', 10)
        self.set_text_color(0, 0, 0)
        self.multi_cell(0, 5, text)
        self.ln()


def create_standardized_pdf(json_data):
    """JSON verisinden PDF √ºretir (√ñzet ve Sertifikalar Eklendi)."""

    # 1. Font Kontrol√º
    font_path = "DejaVuSans.ttf"
    if not os.path.exists(font_path):
        font_path = "Arial.ttf"

    has_custom_font = os.path.exists(font_path)

    # 2. PDF Ba≈ülatma
    if has_custom_font:
        pdf = PDF(font_family='TrFont')
        # Normal, Bold, Italic, BoldItalic hepsi i√ßin aynƒ± fontu tanƒ±mlƒ±yoruz (Hata almamak i√ßin)
        pdf.add_font('TrFont', '', font_path, uni=True)
        pdf.add_font('TrFont', 'B', font_path, uni=True)
        pdf.add_font('TrFont', 'I', font_path, uni=True)
        pdf.add_font('TrFont', 'BI', font_path, uni=True)
    else:
        st.warning("‚ö†Ô∏è T√ºrk√ße font dosyasƒ± bulunamadƒ±. Karakterler d√∂n√º≈üt√ºr√ºl√ºyor.")
        json_data = sanitize_json_recursively(json_data)
        pdf = PDF(font_family='Arial')

    pdf.add_page()
    main_font = pdf.font_family

    # --- √úST Bƒ∞LGƒ∞ (HEADER) ---
    pdf.set_font(main_font, 'B', 16)
    pdf.cell(0, 10, json_data.get('name', ''), 0, 1, 'C')

    pdf.set_font(main_font, 'I', 12)
    pdf.cell(0, 8, json_data.get('title', ''), 0, 1, 'C')

    pdf.set_font(main_font, '', 10)
    pdf.cell(0, 6, json_data.get('location', ''), 0, 1, 'C')

    pdf.set_font(main_font, '', 9)
    pdf.cell(0, 6, json_data.get('contact', ''), 0, 1, 'C')
    pdf.ln(5)

    # --- üÜï SUMMARY (HAKKIMDA) ---
    if json_data.get('summary'):
        pdf.ln(5)  # Biraz bo≈üluk
        pdf.section_title('PROFESSIONAL SUMMARY')
        pdf.section_body(json_data['summary'])

    # --- EDUCATION ---
    if json_data.get('education'):
        pdf.section_title('EDUCATION')
        for edu in json_data['education']:
            pdf.set_font(main_font, 'B', 10)
            pdf.cell(0, 5, f"{edu['degree']}", 0, 1)
            pdf.set_font(main_font, '', 10)
            pdf.cell(0, 5, f"{edu['school']} | {edu['year']}", 0, 1)
            pdf.ln(2)

    # --- EXPERIENCE ---
    if json_data.get('experience'):
        pdf.section_title('EXPERIENCE')
        for exp in json_data['experience']:
            pdf.set_font(main_font, 'B', 10)
            pdf.write(5, f"{exp['role']} | ")
            pdf.set_font(main_font, 'I', 10)
            pdf.write(5, f"{exp['company']}")
            pdf.ln(6)
            pdf.set_font(main_font, '', 9)
            pdf.multi_cell(0, 5, f"- {exp['description']}")
            pdf.ln(3)

    # --- PROJECTS ---
    if json_data.get('projects'):
        pdf.section_title('PROJECTS')
        for proj in json_data['projects']:
            pdf.set_font(main_font, 'B', 10)
            pdf.write(5, f"{proj['name']}")
            if proj.get('tech'):
                pdf.set_font(main_font, 'I', 9)
                pdf.write(5, f" ({proj['tech']})")
            pdf.ln(6)
            pdf.set_font(main_font, '', 9)
            pdf.multi_cell(0, 5, f"{proj['details']}")
            pdf.ln(3)

    # --- üÜï CERTIFICATES (SERTƒ∞Fƒ∞KALAR) ---
    if json_data.get('certificates'):
        pdf.section_title('CERTIFICATES')
        for cert in json_data['certificates']:
            pdf.set_font(main_font, 'B', 10)
            pdf.write(5, f"‚Ä¢ {cert.get('name', '')}")

            # Kurum ve Yƒ±l bilgisi varsa parantez i√ßinde ekleyelim
            extras = []
            if cert.get('issuer'): extras.append(cert['issuer'])
            if cert.get('year'): extras.append(cert['year'])

            if extras:
                pdf.set_font(main_font, '', 10)
                pdf.write(5, f" ({' - '.join(extras)})")

            pdf.ln(5)
        pdf.ln(2)

    # --- SKILLS ---
    if json_data.get('skills'):
        pdf.section_title('TECHNICAL SKILLS')
        skills = json_data['skills']
        pdf.set_font(main_font, '', 10)
        if isinstance(skills, dict):
            for k, v in skills.items():
                pdf.set_font(main_font, 'B', 10)
                pdf.write(5, f"{k.capitalize()}: ")
                pdf.set_font(main_font, '', 10)
                pdf.write(5, v)
                pdf.ln(5)
        else:
            pdf.multi_cell(0, 5, str(skills))
        pdf.ln(2)

    # --- LANGUAGES ---
    if json_data.get('spoken_languages'):
        pdf.section_title('LANGUAGES')
        pdf.section_body(json_data['spoken_languages'])

    # --- INTERESTS ---
    if json_data.get('interests'):
        pdf.section_title('INTERESTS')
        pdf.section_body(json_data['interests'])

    return pdf.output()
# ==========================================
# üõ†Ô∏è YARDIMCI FONKSƒ∞YONLAR
# ==========================================
def process_and_upload_single(name, row, service, cv_cols, silent=False):
    token = str(row.get(COLUMN_TOKEN_ID, "NoToken"))
    if token in get_processed_tokens():
        if not silent: st.warning(f"‚ö†Ô∏è {name} zaten i≈ülenmi≈ü.")
        return False

    pdf_url = ""
    for col in cv_cols:
        val = str(row.get(col, "")).strip()
        if "http" in val:
            pdf_url = val
            break

    if not pdf_url:
        if not silent: st.error(f"{name} i√ßin CV Linki bulunamadƒ±.")
        return False

    # --- YENƒ∞LENEN KISIM: Baƒülantƒ± Y√∂netimi ---
    session = requests.Session()
    # 3 kez deneme yap, hatalar arasƒ±nda bekleme s√ºresini artƒ±r
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    session.mount('https://', HTTPAdapter(max_retries=retries))

    headers = {"Authorization": f"Bearer {st.secrets['general']['typeform_token']}"}

    try:
        # Zaman a≈üƒ±mƒ± (timeout) deƒüerini koruyoruz
        resp = session.get(pdf_url, headers=headers, timeout=60)
        resp.raise_for_status()  # HTTP hatalarƒ±nƒ± yakalar (404, 401 vb.)

        if resp.status_code == 200:
            doc = fitz.open(stream=resp.content, filetype="pdf")
            full_text = "".join([page.get_text() for page in doc])
            cv_json = extract_data_with_gemini(full_text)

            if cv_json:
                new_pdf_bytes = create_standardized_pdf(cv_json)
                cats = cv_json.get("suggested_categories", ["Others"])
                if not isinstance(cats, list): cats = [cats]

                success = upload_to_drive(service, new_pdf_bytes, f"{name}_Standart.pdf", cats)
                if success:
                    save_token(token)
                    if not silent:
                        st.success(f"‚úÖ {name} Drive'a y√ºklendi!")
                    return True

    except requests.exceptions.ConnectionError:
        if not silent: st.error(
            f"üåê Baƒülantƒ± hatasƒ±: ƒ∞nternetinizi kontrol edin veya DNS kaynaklƒ± bir sorun var ({name}).")
    except requests.exceptions.Timeout:
        if not silent: st.error(f"‚è≥ Zaman a≈üƒ±mƒ±: Typeform sunucusu yanƒ±t vermedi ({name}).")
    except Exception as e:
        if not silent: st.error(f"‚ùå Beklenmedik bir hata olu≈ütu ({name}): {e}")

    return False
def sanitize_text(text):
    """T√ºrk√ße karakterleri ƒ∞ngilizce kar≈üƒ±lƒ±klarƒ±na √ßevirir (Font yoksa kullanƒ±lƒ±r)."""
    if not isinstance(text, str):
        return str(text)

    replacements = {
        '≈û': 'S', '≈ü': 's',
        'ƒû': 'G', 'ƒü': 'g',
        'ƒ∞': 'I', 'ƒ±': 'i',
        '√ñ': 'O', '√∂': 'o',
        '√ú': 'U', '√º': 'u',
        '√á': 'C', '√ß': 'c'
    }
    for tr, eng in replacements.items():
        text = text.replace(tr, eng)
    return text.encode('latin-1', 'replace').decode('latin-1')


def sanitize_json_recursively(data):
    """JSON i√ßindeki t√ºm metinleri temizler."""
    if isinstance(data, dict):
        return {k: sanitize_json_recursively(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [sanitize_json_recursively(i) for i in data]
    elif isinstance(data, str):
        return sanitize_text(data)
    else:
        return data

@st.cache_data(ttl=600, show_spinner=False)
def load_data():
    # 3 Kez deneme hakkƒ± veriyoruz
    max_retries = 3

    for attempt in range(max_retries):
        try:
            scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

            # Credential Y√ºkleme
            if "gcp_service_account" in st.secrets:
                creds = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scopes)
            else:
                creds = Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=scopes)

            client = gspread.authorize(creds)

            # Dosyayƒ± A√ßma
            spreadsheet = client.open(SHEET_NAME)
            sheet = spreadsheet.worksheet("ƒ∞ZMƒ∞R CV Form")

            # Veriyi √áekme
            data = sheet.get_all_values()

            if not data: return pd.DataFrame()

            # Ba≈ülƒ±klarƒ± ƒ∞≈üleme (Duplicate Fix)
            headers = data[0]
            rows = data[1:]
            seen = {}
            unique_headers = []
            for col in headers:
                if col in seen:
                    seen[col] += 1
                    unique_headers.append(f"{col}_{seen[col]}")
                else:
                    seen[col] = 0
                    unique_headers.append(col)

            # Ba≈üarƒ±lƒ± olduysa DataFrame'i d√∂nd√ºr ve d√∂ng√ºden √ßƒ±k
            return pd.DataFrame(rows, columns=unique_headers)

        except Exception as e:
            # Hata verirse (ƒ∞nternet kesilirse)
            if attempt < max_retries - 1:  # Son deneme deƒüilse
                time.sleep(2)  # 2 saniye bekle ve tekrar dene
                continue
            else:
                # Son denemede de hata verirse ekrana yaz
                st.error(f"Google Sheets Baƒülantƒ± Hatasƒ± (3 kez denendi): {e}")
                return pd.DataFrame()

def get_processed_tokens():
    if os.path.exists("processed_tokens.txt"):
        with open("processed_tokens.txt", "r") as f: return f.read().splitlines()
    return []


def save_token(token):
    with open("processed_tokens.txt", "a") as f: f.write(f"{token}\n")


# ==========================================
# üñ•Ô∏è ARAY√úZ
# ==========================================

st.set_page_config(page_title="CV Master & Standardizer", layout="wide")
st.title("üõ°Ô∏è ƒ∞zmir CV Form - Standardize Edici")
st.markdown("---")

df = load_data()

if not df.empty:
    st.sidebar.header("üîê Y√∂netici")
    input_pass = st.sidebar.text_input("≈ûifre", type="password")
    is_admin = (input_pass == ADMIN_PASSWORD)

    if is_admin: st.sidebar.success("Admin Modu")

    dept_col = next((col for col in df.columns if col.startswith(COLUMN_DEPARTMENT)), None)
    name_col = next((col for col in df.columns if col.startswith(COLUMN_NAME)), None)
    all_cv_cols = [col for col in df.columns if col.startswith(COLUMN_PDF_URL_BASE)]

    if dept_col:
        depts = df[df[dept_col] != ""][dept_col].unique()
        sel_depts = st.sidebar.multiselect("Filtrele", depts, default=depts)
        filtered_df = df[df[dept_col].isin(sel_depts)]
    else:
        filtered_df = df

    st.sidebar.info(f"Aday: {len(filtered_df)}")

    # Tablo G√∂sterimi
    display_df = filtered_df.copy()
    if not is_admin:
        cols_hide = [c for c in display_df.columns if
                     c.startswith(COLUMN_TOKEN_ID) or c.startswith(COLUMN_PDF_URL_BASE)]
        display_df = display_df.drop(columns=cols_hide, errors='ignore')

    st.dataframe(display_df, use_container_width=True)

    # --- ƒ∞≈ûLEM PANELƒ∞ ---
    st.markdown("---")
    st.subheader("üìÑ Standart Formatlƒ± CV & Drive Entegrasyonu")

    c1, c2, c3 = st.columns([1, 1, 1])

    with c1:
        sel_name = st.selectbox("Aday Se√ß:", filtered_df[name_col].tolist()) if name_col else None

    # Drive servisini hazƒ±rlayalƒ±m
    drive_service = get_drive_service()

    with c2:
        st.write("**Bireysel ƒ∞≈ülem**")
        if sel_name and st.button("Se√ßiliyi Drive'a G√∂nder"):
            row = filtered_df[filtered_df[name_col] == sel_name].iloc[0]
            # (Burada PDF olu≈üturma ve Drive'a y√ºkleme mantƒ±ƒüƒ± √ßalƒ±≈üacak)
            process_and_upload_single(sel_name, row, drive_service, all_cv_cols)

    with c3:
        st.write("**Toplu ƒ∞≈ülem**")
        if st.button(f"Filtreli {len(filtered_df)} Ki≈üiyi Drive'a G√∂nder"):
            # G√ºncel i≈ülenmi≈ü token listesini al
            processed_tokens = get_processed_tokens()

            # Sadece hen√ºz i≈ülenmemi≈ü olanlarƒ± filtrele
            to_process_df = filtered_df[~filtered_df[COLUMN_TOKEN_ID].isin(processed_tokens)]

            if to_process_df.empty:
                st.info("Se√ßili listedeki t√ºm adaylar zaten daha √∂nce g√∂nderilmi≈ü.")
            else:
                progress_bar = st.progress(0)
                status_text = st.empty()
                total = len(to_process_df)

                for i, (idx, row) in enumerate(to_process_df.iterrows()):
                    c_name = row[name_col]
                    status_text.text(f"ƒ∞≈üleniyor ({i + 1}/{total}): {c_name}")

                    process_and_upload_single(c_name, row, drive_service, all_cv_cols, silent=True)

                    progress_bar.progress((i + 1) / total)
                    time.sleep(1)  # Kota korumasƒ± i√ßin kƒ±sa mola

                st.success(f"‚úÖ Yeni {total} aday Drive'a y√ºklendi!")
                status_text.empty()